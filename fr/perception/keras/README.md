# IV. Perception avec Keras

**tensorflow** et **keras** sont deux modules Python qui permettent de construire des r√©seaux de neurones apprenants. Nous allons les utiliser pour entra√Æner un r√©seau de neurones √† reconna√Ætre des chiffres √©crits manuellement au feutre avec diff√©rentes calligraphies, ce que l'on appelle aussi **classifier**.

## Pr√©requis

* BAC+2 et +
* Bonne compr√©hension de Python et numpy

## Diapositives

{% pdf src="https://files.ros4.pro/perception.pdf", width="100%", height="565px" %}{% endpdf %}

## 0. Installation

üì• Le code source √† t√©l√©charger se trouve √† [cet emplacement](https://github.com/cjlux/ros4pro_perception).

Une fois t√©l√©charg√©, vous devez installer les packages Python requis en tapant la commande suivante (depuis le dossier `ros4pro_perception`) :

```bash
pip3 install -r requirements.txt
```

## 1. Documentation

Pour anlyser et compl√©ter les codes fournis, vous aurez besoin de consulter plusieurs documentations.

De mani√®re g√©n√©rale, vous aurez besoin de numpy. Si vous n'√™tes pas familier avec ce module, vous pouvez consulter:

* [Numpy cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)
* [Numpy Documentation](https://numpy.org/devdocs/user/quickstart.html)

Pour la partie d√©tection des faces des cubes et pr√©-processing, nous utiliserons `scikit-image`:

* [Scikit-Image Documentation](https://scikit-image.org/docs/stable)

Enfin, pour la partie reconnaissance, nous utilsons le module `keras` inclus dans le module `tensorflow` depuis sa version 2. Un point d'entr√©e sur l'API S√©quentielle de keras peut √™tre consult√© sur cette page :

* [keras API Sequential](https://www.tensorflow.org/guide/keras/sequential_model?hl=fr)

## 2. Partie apprentissage

### 2.0 Travail pr√©liminaire avec les notebooks Jupyter üìí

En tapant la commande `jupyter notebook` depuis le dossier `ros4pro_perception` vous pouvez charger les deux notebooks *√† trous* pour la prise en main du *machine learning* avec **tensorflow** et **keras** :

* `notebook/TP1_MNIST_dense.ipynb` : utiliser ce notebook pour l'acquisition des bases sur le *machine learning*, la banque d'images MNIST utilis√©e pour l'entra√Ænement des r√©seaux, et la construction d'un r√©seau de neurones dense, son entra√Ænement et son exploitation, conduisant √† un taux de reconnaissance des images MNIST voisin de 98 %.

* `notebook/TP2_MNIST_convol.ipynb` : utiliser ensuite ce notebook pour la construction d'un r√©seau convolutif, son entra√Ænement avec les images MNIST et son exploitation, conduisant √† un taux de reconnaissance voisin de 99 %.

Une fois familiaris√© avec les principes de construction des r√©seaux denses et convolutifs, vous pouvez utiliser les programmes Python du r√©pertoire `src/`.

### 2.1  Chargement des images MNIST

Ouvrir le fichier `src/learning.py`, prendre connaissance du code, puis lancer le programme.

Avant d'appuyer sur entr√©e, assurez-vous que vous savez r√©pondre aux questions suivantes :

* Que contiennent les variables `x_train` et `y_train` ?

* Pourquoi la fonction `load_data` renvoie-t-elle √©galement les donn√©es `x_test` et `y_test` ?

* Quelles sont les formes respectives de `x_train` et `y_train` ?

### 2.2 Pr√©visualisation des donn√©es brutes

Appuyer sur entr√©e pour continuer, et observer les images :

* Quelles sont les valeurs des pixels blancs et noirs ?

* Observer les donn√©es et leurs labels. Toutes les images sont elles simples √† classifier correctement ? Ferriez vous des erreurs en les classifiants ?

### 2.3 Pr√©paration des donn√©es

Fermer la fen√™tre et appuyer √† nouveau sur entr√©e :

* Quelles sont les formes de `x_train` et `y_train` maintenant ?

* Pourquoi ces changements ?

### 2.4 Pr√©visualisation des donn√©es pr√©par√©es

Appuyer √† nouveau sur entr√©e et observer les images :

* Quelles sont les valeurs des pixels blanc et noirs maintenant ?

* Regarder la fonction `prepare_input` : quelle transformation des images est effectu√©e ?

### 2.5 Le mod√®le du r√©seau convolutif

Arr√™ter le script. Dans le fichier source `learning.py` modifier la fonction `build_model` pour impl√©menter un r√©seau convolutif semblable √† celui impl√©ment√© dans le notebook `TP2_MNIST_convol.ipynb`.

Relancer le script et faire d√©filer jusqu'√† la partie 2.5 (vous pouvez modifier `SHOW_SAMPLES` pour ne pas afficher toutes les fen√™tres...) :

* v√©rifier les informations des couches sur le r√©sum√© du mod√®le...

### 2.6 La fonction de co√ªt et l'optimiseur

Arr√™ter le script et v√©rifier :

* la fonction de co√ªt et l'optimiseur utilis√©s dans l'appel √† `modele.compile(...)`

### 2.7 Entra√Ænement

* Observer la fonction `train_model` : v√©rifier la pr√©sence et le param√©trage de la gestion de l'_over-fit_.

* Relancer le code jusqu'au d√©clenchement de la partie 2.7 : vous devriez voir les it√©rations d'entra√Ænement se succ√©der et s'arr√™ter sur un √©v√©nement __early stopping__.

### 2.8 Poids appris

Appuyer sur entr√©e pour visualiser les noyaux convolutifs appris par le r√©seau de neurones :

* Observant les noyaux de la premi√®re couche : arrivez vous √† distinguer le genre de _features_ qui seront extraites par chacun ?

* Pouvez vous en faire de m√™me pour la deuxi√®me couche ?

### 2.9 Activations

Appuyer sur entr√©e, puis entrer un indice (un entier de valeur inf√©rieure a 12000 (pourquoi 1200 ?)) :

* Apr√®s la premi√®re couche de convolution, les _features_ extraites correspondent-elles √† celles que vous imaginiez ?

* Apr√®s la premi√®re couche de _pooling_, les _features_ pr√©sentes auparavant sont-elles conserv√©es ?

* Apr√®s la deuxi√®me couche de _pooling_, diriez vous que de l'information spatiale est toujours pr√©sente ? Autrement dit, les activations ressemblent elles toujours √† des images ?

### 2.10 Entra√Ænement final

Arr√™ter le script. Jusqu'√† pr√©sent, nous avons travaill√© sur l'ensemble des images montrant des chiffres de '0' √† '9', mais pour la suite nous n'aurons besoin que des images de '1' et de '2' :

* Changer la valeur de la variable `CLASSES` pour ne garder que les classes qui nous int√©ressent.

* Changer `SHOW_SAMPLES`, `SHOW_WEIGHTS` et `SHOW_ACTIV` si vous d√©sirez moins d'affichage graphique...

* Entra√Æner le r√©seau avec le nouveau jeu de donn√©es r√©duites, puis le sauvegarder en donnant le nom d'un r√©pertoire o√π sauvegarder les fichiers du r√©seau entra√Æn√©.

Vous pouvez passer maintenant √† la **Partie Vision** qui permettra, une fois achev√©e, d'observer les inf√©rences du r√©seau avec les images des cubes correctement trait√©es...

## 3. Partie Vision

Le but de la partie Vision est de traiter les images fournies par la cam√©ra du robot :

![212.png](img/212.png)

pour trouver les contours des cubes :

![212_contours.png](img/212_contours.png)

et extraire des images compatibles MNIST :

![212_contours.png](img/2.png)

qui seront envoy√©es au r√©seau de neurone pour classification en '1' ou '2'...

### 3.1 Pr√©sentation des donn√©es

Ouvrir le fichier `src/detection.py` et lancer le script. Une des images exemple issue de la cam√©ra du robot appara√Æt :

* Observer les valeurs de pixels ? Quelles sont les valeurs de pixels blancs et noirs ?

* De mani√®re g√©n√©rale, la face des cubes est-elle semblable aux images MNIST ?

### 3.2 Binarisation de l'image

Appuyer sur entr√©e pour afficher l'image binaris√©e :

* Pouvez vous penser √† un algorithme permettant d'arriver √† un r√©sultat similaire ?

Dans le code, observer la fonction `binarize` :

* √Ä quoi sert la fonction `threshold_otsu` ? (voir au besoin la documentation  `scikit-image`).

En commentant successivement les lignes les utilisant, observer l'impact de chacune des fonctions suivantes :

* `closing`
* `clear_border`
* `convex_hull_object`

Pourquoi faut-il √©viter d'avoir des cubes qui touchent les bords de l'image ?

### 3.3 Recherche des contours des cubes

Appuyer sur entr√©e pour faire d√©filer quelques images dont les contours ont √©t√© d√©tect√©s.

Observer la fonction `get_box_contours`:

* √Ä quoi sert la fonction `label` ?
* √Ä quoi sert le param√®tre `area` ?
* √Ä quoi sert la fonction numpy `argsort` utilis√©e √† la fin pour le r√©-arragement des contours ? 
Pourquoi cette op√©ration est elle importante ?

### 3.4 Extraction des vignettes

Appuyer sur entr√©e pour faire d√©filer quelques images dont les vignettes ont √©t√© extraites.

Observer la fonction `get_sprites`: Qu'est ce qu'une "transformation projective" ?

### 3.5 Pr√©paration des images

Pendant la phase d'apprentissage, nous avons √©tudi√© la pr√©paration qui √©tait faite des images.

Les vignettes pr√©sent√©es au r√©seau de neurones doivent aussi √™tre trait√©es pour avoir les m√™mes caract√©ristiques que les images d'entrainement MNIST :

* Remplir la fonction `preprocess_sprites` pour effectuer ce traitement...

Une fois fait, ex√©cuter le script jusqu'√† la fin et conclure sur l'allure des images trait√©es.

Vous pouvez maintenant ouvrir le fichier `main.py` pour tester l'int√©gration de la d√©tection et de la reconnaissance par r√©seau apprenant...

## 4. Int√©gration

Il est maintenant temps d'int√©grer les deux parties du pipeline pour l'utilisation finale. Ouvrez le fichier `main.py` √† la racine du projet.

Pour que les deux parties du pipeline s'adaptent correctement, vous avez compl√©t√© la fonction `preprocess_sprites` pour mettre les vignettes renvoy√©es par la partie d√©tection dans un format compatible avec celui des images MNIST.

Ex√©cuter maintenant le programme `main.py` : donner le nom d'un dossier qui contient les fichiers des poids du r√©seau entra√Æn√© et vous devriez commencer √† obtenir la reconnaissance des chiffres '1' et '2' dans les images fournies.

Il faudra certainement refaire plusieurs fois l'entra√Ænement du r√©seau en jouant sur plusieurs param√®tres avant d'obtenir un r√©seau entra√Æn√© qui fonctionne correctement :

* la valeur de la graine `SEED` peut conduire √† un √©tat initial des poids du r√©seau qui donne un entra√Ænement meilleur ou pas...

* augmenter/diminuer `BATCH_SIZE` peut modifier les temps de calcul et la qualit√© du r√©seau entra√Æn√©...

* augmenter/diminuer le param√®tre `patience` du callback `EarlyStopping`...

* enfin, tous les param√®tres qui d√©finissent les couches de convolution et de __spooling__ du r√©seau convolutif sont autant de possibilit√©s d'am√©liorer ou pas les performances du r√©seau entra√Æn√©....

√Ä vous de jouer pour obtenir un r√©seau entra√Æn√© classifiant le mieux possible les chiffres '1' et '2' dans les images fournies par la cam√©ra du robot...

Pour confirmer la qualit√© de votre r√©seau entra√Æn√© vous pouvez enregistrer vos propres fichiers PNG avec les images faites avec la cam√©ra du robot en utilisant le service ROS `/get_image`. Aidez-vous des idications du paragraphe __2.4. R√©cup√©rer les images de la cam√©ra en Python__ dans la section [Manipulation/Poppy Ergo Jr](https://learn.ros4.pro/fr/manipulation/ergo-jr/) : vous pouvez ajouter une instruction `cv2.imwrite(image, <file_name>)` pour √©crire vos propres fichiers PNG dans le r√©pertoire `data/ergo_cubes/perso` et modifier en cons√©quence la variable `img_dir` du fichier `main.py`.

Lancer le programme et observer les performances de votre r√©seau op√©rant sur vos propres images.
