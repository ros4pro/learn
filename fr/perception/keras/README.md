# IV. Perception avec Keras

**tensorflow** et **keras** sont deux modules Python qui permettent de construire des r√©seaux de neurones apprenants. Nous allons les utiliser ici sur des imagettes sur lesquelles sont inscrits des chiffres √©crits manuellement au feutre avec diff√©rentes calligraphies. Le r√©seau de neurones que vous allez cr√©er devra apprendre √† d√©terminer quel chiffre est marqu√©, ce que l'on appelle **classifier**.

## Pr√©requis

* BAC+2 et +
* Bonne compr√©hension de Python et numpy

## Diapositives

{% pdf src="https://files.ros4.pro/perception.pdf", width="100%", height="565px" %}{% endpdf %}

## 0. Installation

üì• Le code source √† t√©l√©charger se trouve √† [cet emplacement](https://github.com/cjlux/ros4pro_perception).

Une fois t√©l√©charg√©, vous devez installer les packages Python requis en tapant la commande suivante (depuis le dossier `ros4pro_perception`) :

```bash
pip install -r requirements.txt
```

## 1. Documentation

Pour anlyser et compl√©ter les codes fournis, vous aurez besoin de consulter plusieurs documentations.

De mani√®re g√©n√©rale, vous aurez besoin de numpy. Si vous n'√™tes pas familier avec ce module, vous pouvez consulter:

* [Numpy cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)
* [Numpy Documentation](https://numpy.org/devdocs/user/quickstart.html)

Pour la partie d√©tection des faces des cubes et pr√©-processing, nous utiliserons `scikit-image`:

* [Scikit-Image Documentation](https://scikit-image.org/docs/stable)

Enfin, pour la partie reconnaissance, nous utilsons le `keras` inclus dans le module `tensorflow` depuis sa version 2. Un point d'entr√©e sur l'API S√©quentielle peut √™tre consult√© sur cette page :

* [keras API Sequential](https://www.tensorflow.org/guide/keras/sequential_model?hl=fr)

## 2. Partie apprentissage

### 2.0 Travail pr√©liminaire avec les notebooks Jupyter üìí

En tapant la commande `jupyter notebook` depuis le dossier `ros4pro_perception` vous pouvez charger les deux notebooks *√† trous* pour la prise en main du *machine learning* avec **tensorflow-keras** :

* `notebook/TP1_MNIST_dense.ipynb` : utiliser ce notebook pour l'acquisition des bases sur le *machine learning*, la banque d'images MNIST utilis√©e pour l'entra√Ænement des r√©seaux, et la construction d'un r√©seau de neurones dense, son entra√Ænement et son exploition, conduisant √† un taux de reconnaissance des images MNIST voisin de 98 %.

* `notebook/TP2_MNIST_convol.ipynb` : utiliser ensuite ce notebook pour la construction d'un r√©seau convolutif, son entra√Ænement avc les images MNIST et son exploition, conduisant √† un taux de reconnaissance voisin de 98 %.

Une fois familiaris√© avec les principes de construction des r√©seaux denses et convolutifs, vous pouvez aborder l'exploitation de vos acquis en utilisant les programmes Python du r√©pertoire `src/`.

### 2.1  Chargement des images MNIST

Ouvrir le fichier `src/learning.py`, prendre connaissance du code, puis lancer le programme.

Avant d'appuyer sur entr√©e, assurez-vous que vous savez r√©pondre aux questions suivantes :

* Que contiennent les variables `x_train` et `y_train` ?

* Pourquoi la fonction `load_data` renvoie-t-elle √©galement les donn√©es `x_test` et `y_test` ?

* Quelles sont les formes respectives de `x_train` et `y_train` ?

### 2.2 Pr√©visualisation des donn√©es brutes

Appuyer sur entr√©e pour continuer, et observer les images :

* Quelles sont les valeurs des pixels blancs et des pixels noirs ?

* Observer les donn√©es et leurs labels. Toutes les images sont elles simples √† classifier correctement ? Ferriez vous des erreurs en les classifiants ?

### 2.3 Pr√©paration des donn√©es

Fermer la fen√™tre et appuyer √† nouveau sur entr√©e :

* Quelles sont les formes de `x_train` et `y_train` maintenant?

* Pourquoi ces changements ?

### 2.4 Pr√©visualation des donn√©es pr√©par√©es

Appuyer √† nouveau sur entr√©e et observer les images:

* Quelles sont les valeurs des pixels blanc et des pixels noirs maintenant?

* Regarder la fonction `prepare_input` : quelle transformation des images est effectu√©e?

### 2.5 Le mod√®le du r√©seau convolutif

Arr√™ter le script. Dans le fichier source `learning.py` modifier la fonction `build_model` pour impl√©menter le r√©seau convolutif *LeNet* vu dans le notebook `TP2_MNIST_convol.ipynb`.

Une fois fait, relancer le script et faire d√©filer jusqu'√† la partie 2.5 (vous pouvez modifier `SHOW_SAMPLES` pour ne pas afficher toutes les fen√™tres...) :

* v√©rifier les informations des couches sur le r√©sum√© du mod√®le...

### 2.6 La fonction de co√ªt et l'optimiseur

Arr√™ter le script. Dans le notebook du TP1 nous avons vu que la fonction de co√ªt **entropie crois√©e** (*cross entropy*) √©tait la plus adapt√©e au calcul d'erreur avec des sorties au format *hot-one* :

* V√©rifier que c'est bien la fonction de co√ªt utilis√©e dans l'appel √† `modele.compile(...)`

L'optimiseur est utilis√© pour se d√©placer vers un minimum sur la surface dessin√©e par la fonction de co√ªt dans l'espace des param√®tres.

Un des algorithmes les plus simples est la __descente de gradient__ (GD) et consiste √† se d√©placer dans le sens de la pente la plus forte √† chaque pas de temps :

* Sous quelle hypoth√®se cet algorithme permet-il de trouver le minimum global de la fonction de co√ªt selon vous ?

* Pensez vous que cette hypoth√®se soit v√©rifi√©e pour les r√©seaux de neurones ?

* Que se passe-t-il si cette hypoth√®se n'est pas v√©rifi√©e ?

__Adam__ est un optimiseur plus complexe que GD. Sur l'image suivante, on voit plusieurs optimiseurs se d√©placer sur une fonction de co√ªt :
![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)
(source : github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)

Concentrez-vous sur Adam et GD:

* Quelle semble √™tre la caract√©ristique de Adam compar√©e a GD ?

Une autre caracteristique de l'algorithme GD, est que le pas effectu√© √† chaque it√©ration est fixe. L'image suivante montre Adam et GD dans un cas ou la pente devient tr√©s forte :
![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)
(source : github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)

* GD arrive-t-il √† converger ? Comprenez vous pourquoi ?

* Adam ne semble pas soumis au m√™me probl√™me que GD ? Quelle autre caract√©ristique de Adam cela montre t-il ?

pour finir :

* Quelle conclusion pouvez vous tirer sur l'utilit√© de GD pour entra√Æner des r√©seaux de neurones ?

* Quel est l'optimiseur utilis√© dans le code ?

### 2.7 Entra√Ænement

* Observer la fonction `train_model` pour v√©rifier la pr√©sence et le param√©trage du m√©canisme de gestion de l'_over-fit_.

* Relancer le code jusqu'au d√©clenchement de la partie 2.7 : vous devriez voir les it√©rations d'entra√Ænement se succ√©der et s'arr√™ter sur un √©v√©nement __early stopping__.

### 2.8 Poids appris

Appuyer sur entr√©e pour visualiser les noyaux convolutifs appris par le r√©seau de neurones :

* En observant les noyaux de la premi√®re couche, arrivez vous √† distinguer le genre de _features_ qui seront extraites par chacun ?

* Pouvez vous en faire de m√™me pour la deuxi√®me couche ?

### 2.9 Activations

Appuyer sur entr√©e, puis entrer un indice (un entier de valeur inf√©rieure a 12000) :

* Apr√®s la premi√®re couche de convolution, les _features_ extraites correspondent elles √† celles que vous imaginiez ?

* Apr√®s la premi√®re couche de _pooling_, les _features_ pr√©sentes auparavant sont-elles conserv√©es ?

* Apr√®s la deuxi√®me couche de _pooling_, diriez vous que de l'information spatiale est toujours pr√©sente ? Autrement dit, les activations ressemblent elles toujours √† des images ?

### 2.10 Entra√Ænement final

Arr√™ter le script. Jusqu'√† pr√©sent, nous avons travaill√© sur l'ensemble des images montrant des chiffres de 0 √† 9, mais pour la suite nous n'aurons besoin que des images de 1 et de 2 :

* Changer la valeur de la variable `CLASSES` pour ne garder que les classes qui nous int√©ressent.

* Changer `SHOW_SAMPLES`, `SHOW_WEIGHTS` et `SHOW_ACTIV` si vous d√©sirez moins d'affichage graphique...

* Entra√Æner le r√©seau avec le nouveau jeu de donn√©es r√©duites, puis le sauvegarder en donnant le nom d'un r√©pertoire o√π sauvegarder les fichiers du r√©seau entra√Æn√©.

Vous pouvez passer maintenant √† la **Partie Vision** qui permettra, une fois achev√©e, d'observer les inf√©rences du r√©seau avec les images des cubes correctement trait√©es...

## 3. Partie Vision

Le but de la partie Vision est de traiter les images fournies par la cam√©ra du robot :

![212.png](img/212.png)

pour trouver les contours des cubes :

![212_contours.png](img/212_contours.png)

et en extraire des images compatibles MNIST :

![212_contours.png](img/2.png)

qui seront envoy√©es au r√©seau de neurone pour classification en '1 ou '2'...

### 3.1 Pr√©sentation des donn√©es

Ouvrir le fichier `src/detection.py` et lancer le script. Une image exemple issue de la cam√©ra du robot devrait vous √™tre pr√©sent√©e :

* Observer les valeurs de pixels ? Quelles sont les valeurs de pixels blancs et noirs ?

* De mani√®re g√©n√©rale, la face des cubes est elle semblable aux images MNIST ?

### 3.2 Binarisation de l'image

Appuyer sur entr√©e, et vous devriez voir s'afficher une image binaris√©e :

* Pouvez vous penser √† un algorithme permettant d'arriver √† un r√©sultat similaire ?

Dans le code, observer la fonction `binarize` :

* √Ä quoi sert la fonction `threshold_otsu` ? (voir au besoin la documentation  `scikit-image`).

* Ajouter une ligne pour afficher la valeur de `thresh` √† chaque appel de la fonction. Cette valeur est elle la m√™me pour toutes les images ?

En commentant successivement les lignes les utilisant, observer l'impact de chacune des fonctions suivantes :

* √Ä quoi sert la fonction `closing` ?
* √Ä quoi sert la fonction `clear_border` ?
* √Ä quoi sert la fonction `convex_hull_object` ?
* Conclure en r√©sumant l'encha√énement des op√©rations effectu√©es dans la fonction `binarize`.

* pourquoi faut-il √©viter d'avoir des cubes qui touchent les bords de l'image ?

### 3.3 Recherche des contours des cubes

Appuyer sur entr√©e pour faire d√©filer quelques images dont les contours ont √©t√© d√©tect√©s.

Observer la fonction `get_box_contours`:

* √Ä quoi sert la fonction `label` ?
* √Ä quoi sert le param√®tre `area` ?
* √Ä quoi sert la fonction numpy `argsort` utilis√©e √† la fin pour le r√©-arragement des contours ? Pourquoi cette op√©ration est elle importante ?
* Conclure en r√©sumant l'encha√Ænement des op√©rations effectu√©es dans la fonction `get_box_contours`.

### 3.4 Extraction des vignettes

Appuyer sur entr√©e pour faire d√©filer quelques images dont les vignettes ont √©t√© extraites.

Observer la fonction `get_sprites`:

* Qu'est ce qu'une "transformation projective" ?

### 3.5 Pr√©paration des images

Pendant la phase d'apprentissage, nous avons √©tudi√© la pr√©paration qui √©tait faite des images.

Les vignettes que nous allons pr√©senter au r√©seau de neurones doivent aussi √™tre trait√©es pour avoir les m√™mes caract√©ristiques que les images d'entrainement MNIST :

* Remplir la fonction `preprocess_sprites` pour effectuer ce traitement...

Une fois fait, ex√©cuter le script jusqu'√† la fin et conclure sur l'allure des images trait√©es.

Vous pouvez maintenant ouvrir le fichier `main.py` pour tester l'int√©gration de la d√©tection et de la reconnaissance par r√©seau apprenant...

## 4. Int√©gration

Il est maintenant temps d'int√©grer les deux parties du pipeline pour l'utilisation finale. Ouvrez le fichier `main.py` √† la racine du projet.

Pour que les deux parties du pipeline s'adaptent correctement, vous avez compl√©t√© la fonction `preprocess_sprites` qui permet de mettre les vignettes renvoy√©es par la partie d√©tection dans un format compatible avec celui des images MNIST.

Ex√©cuter maintenant le programme `main.py` : donner le nom d'un dossier qui contient les fichiers des poids du r√©seau entra√Æn√© et vous devriez commencer √† obtenir la reconnaissance des chiffres '1' et '2' dans les images fournies.

Il faudra certainement refaire plusieurs fois l'entra√Ænement du r√©seau en jouant sur plusieurs param√®tres avant d'obtenir un r√©seau entra√Æn√© qui fonctionne correctement :

* changer la valeur de la graine `SEED` peut conduire √† un √©tat initial des poids du r√©seau qui donne un entra√Ænement meilleur ou pas...

* augmenter/diminuer `BATCH_SIZE` peut aussi am√©liorer ou pas les performances du r√©seau entra√Æn√©...

* augmenter/diminuer le param√®tre `patience` du callback `EarlyStopping`...

* enfin, tous les param√®tres qui d√©finissent les couches de convotution et de __spoling__ du r√©seau convolurif sont autant de possibilit√©s d'am√©liorer ou pas les performances du r√©seau entra√Æn√©....

√Ä vous de jouer pour obtenir un r√©seau entra√Æn√© discriminant le mieux possible les chiffres '1' et '2' des images extraites des captures de la cam√©ra duu robot...

Pour confirmer la qualit√© de votre r√©seau entra√Æn√© vous pouvez enregistrer vos propres fichiers PNG avec les images faites avec la cam√©ra du robot en utilisant le service ROS `/get_image`. Aidez-vous des idications du paragraphe __2.4. R√©cup√©rer les images de la cam√©ra en Python__ dans la section [Manipulation/Poppy Ergo Jr](https://learn.ros4.pro/fr/manipulation/ergo-jr/) en compl√©tant avec l'instruction `cv2.imwrite(image, file_name)` pour l'√©criture du fichier PNG. Vous pouvez d√©poser vos fichiers dans le r√©pertoire `data/ergo_cubes/perso` et modifier en cons√©quence la variable `im_dir` du fichier `main.py`. Lancez le programme et observez la performance de votre algorithme sur les donn√©es de votre propre environnement.
