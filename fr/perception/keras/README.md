# ROS4PRO : Journ√©e Perception
## Installation

üíªüìÄ  Pour effectuer cet atelier, vous devez installer quelques paquets. Pour cela,
positionnez vous √† la racine du d√©p√¥t et ex√©cutez la ligne suivante:
```
pip install -r requirements.txt
```

## Paquets et documentation

üìö Pour effectuer ce travail, vous aurez besoin de manipuler majoritairement 4
biblioth√®ques python de calcul scientifique:
+ _numpy_: Cette biblioth√®que propose un tableau n-dimensionnel, ainsi que des
  op√©rations pour les manipuler. Ces op√©rations sont cod√©es en C pour une 
  meilleure performance (python lui-m√™me est tr√©s lent). Ce tableau est __la__ 
  structure de donn√©e la plus importante pour le machine learning en python. 
  Dans notre cas, les images seront toujours encod√©es sous forme de tableau 
  numpy. Attention: Les tableaux numpy et les listes python sont des objets
  diff√©rents. Il arrive que dans le code, on doive passer de l'un √† l'autre.
  Faites bien attention √† garder en t√™te le type de vos objets quand vous
  r√©fl√©chissez √† votre code.
+ _scipy_: Cette biblioth√®que propose un ensemble d'algorithme de calcul
  scientifique de base, rapides car souvent d√©velopp√©s en C √©galement. Scipy 
  utilise √©galement les tableaux numpy comme structure de donn√©e principale.
+ _scikit-image_: Cette biblioth√®que propose un ensemble d'algorithmes de
  traitement d'images d√©velopp√©s en python (semblable √† `opencv`). Cette
  librairie contient beaucoup d'algorithmes, et nous en utiliserons certains.
  Notez que dans certains cas, les algorithmes peuvent √™tre assez lent √†
  ex√©cuter. Dans ce cas, il peut √™tre int√©ressant de se tourner vers scipy si
  les m√™mes algo sont disponibles.
+ _tensorflow-keras_: Cette biblioth√®que propose un ensemble d'outils permettant de
  construire des r√©seaux de neurones. En outre, elle fait essentiellement deux
  choses: Elle permet de d√©river automatiquement le code de la passe backward
  √† partir du code de la passe forward, et elle permet d'ex√©cuter ce code sur
  des ressources h√©t√©rog√®nes comme des gpus, ou des grappes de calcul. Dans notre
  cas, nous n'utiliserons que les cpu. Depuis la version 2.0 (que nous
  utiliserons), tensorflow utilise √©galement des tableaux numpy comme structure
  de donn√©e.

üìö Il existe de nombreuses ressources pour chacune de ces biblioth√®ques, mais je vous
conseille de regarder celles ci si vous √™tes coinc√©s:
+ [Numpy cheatsheet](https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf)
+ [Numpy Documentation](https://numpy.org/devdocs/user/quickstart.html)
+ [Scikit-Image Documentation](https://scikit-image.org/docs)
+ [Keras Documentation](https://keras.io/)
+ [Scipy ndimage documetation](https://docs.scipy.org/doc/scipy/reference/ndimage.html)

## 1. Partie D√©tection

Dans cette partie, vous allez d√©velopper et mettre au point un syst√®me de
d√©tection de cubes dans une image. A partir d'une image captur√©e par votre Poppy Ergo Jr,
telle que celle-ci :

![img](../img/12.png)

Vous devrez √©crire un programme permettant d'extraire une (ou plusieurs si
besoin) imagettes comme celle-ci :

![img](../img/sprite.png)

üêç Ouvrez le fichier `src/detection.py`. Durant toute la dur√©e du tp, vous 
devrez lancer le script en ex√©cutant la ligne de commande:
```shell
$ python detection.py
```

‚ùå Notez qu'√† tout moment, vous pouvez interrompre le script en appuyant sur 
`Ctrl-C` deux fois d'affil√©e. Il se peut √©galement qu'il faille fermer les
fen√™tres encore ouverte pour que le programme se termine correctement.

üêç En python, il n'existe pas de fonction `main` comme dans d'autre language. Dans
notre cas, le script d√©marre √† partir de la ligne suivante:
```python
#---------------------------- MAIN

if __name__ == "__main__":

    # Le script d√©marre son ex√©cution i√ßi.
    # ...
```

‚ôØ N'h√©sitez pas √† commenter les sections que vous avez d√©j√† effectu√© pour que le
script s'ex√©cute plus vite √† chaque fois.

### 1.1 Pr√©sentation des donn√©es

Le script commence par charger des donn√©es de test pr√©alablement captur√©es, dans
un environnement contr√¥l√©. Cependant, la fonction `show_image` qui permet
d'afficher ces images n√©cessite que vous remplissiez quelques fonctions, qui
manipulent des tableaux numpy.

üêç Remplissez les fonctions:
+ `get_image_min`
+ `get_image_max`
+ `get_image_shape`
+ `get_image_dtype`

Une fois ces fonctions remplies, vous pouvez d√©marrer le script. Les images
d'exemple devraient alors vous √™tre pr√©sent√©es.

‚úç R√©pondez aux questions suivantes:
+ Quelle est la forme du tableau ? √Ä quoi corresponde ces dimensions ?
+ Observez les valeurs minimales et maximales du tableau. Sont elles les m√™mes pour toutes les images ? 
+ Quel est le type des donn√©es enregistr√©es dans le tableau numpy? Pourquoi est-ce le cas? Ce type de donn√©e est il adapt√© aux r√©seaux de neurones ? 
+ De mani√®re g√©n√©rale, trouvez vous que la face des cubes est semblable aux images du dataset mnist que nous allons devoir utiliser pour l'apprentissage ? 

### 1.2 Segmentation de l'image

Maintenant, nous allons passer √† la segmentation de l'image. L'objectif de cette
√©tape est de d√©tecter, pour chacun des pixel, si il appartient √† un cube, ou si
il appartient au fond de la sc√®ne. Pour ce faire, nous allons utiliser une
approche classique nomm√©e le __thresholding__. Les grandes √©tapes de
l'algorithme sont les suivantes:
+ On transforme l'image en niveaux de gris
+ On cr√©e une image binaire gr√¢ce √† une op√©ration de seuillage
+ On nettoie l'image binaire des artefacts du seuillage
+ On s√©pare les diff√©rentes zones blanches de l'image binaire
+ On nettoie chacune des zones blanches pour qu'elle se rapproche d'une face de
  cube blanc pleins.
  
Cet algorithme est contenu dans la fonction `segment_thresholding`, qui doit
renvoyer une liste d'images binaires contenant chacune le masque d'un des cubes
pr√©sent sur l'image.

üëÄ Observez la fonction `segment_thresholding`. La premi√®re √©tape de la
segmentation consiste √† transformer l'image, jusqu'alors en couleurs, en une
image en niveaux de gris.

üêç Remplissez le code de la fonction `turn_to_grey`.

‚úç R√©pondez aux questions suivantes : 
+ Pouvez vous penser √† plusieurs mani√®re de transformer une image en RGB en une image en niveaux de gris ? 
+ Y a t il une diff√©rence √† utiliser une m√©thode en particulier ?

Une fois la fonction remplie, l'ex√©cution du script devrait montrer vos images
en noir et blanc.

‚úç  R√©pondez aux questions suivantes :
+ Quelle est la taille de l'image maintenant ? 
+ Quels sont les valeurs maximales et minimales ?
+ Quel est le type de donn√©e? Est-il le m√™me ou a-t-il chang√© ?

Nous allons √† pr√©sent chercher √† s√©parer les pixels de l'image en deux
cat√©gories, les pixels clairs (√† priori appartenant aux cubes) et les pixels
fonc√©s (√† priori appartenant au fond). Pour cela, nous allons simplement
chercher une valeur _seuil_ (threshold en anglais) et s√©parer en deux les pixels
selon ce seuil. Il existe plusieurs mani√®res de trouver le seuil optimal. Vous
pouvez le chercher √† la main, ou utiliser des algorithmes automatis√©s pour le
trouver. La librairie `scikit-image` contient plusieurs algorithmes de
seuillage. 

üêç  Remplissez la fonction `compute_image_threshold` en essayant plusieurs strat√©gies de thresholding.
 
‚úç R√©pondez aux questions suivantes:
+ Quelle strat√©gie avez vous essay√©? 
+ Voyez vous une diff√©rence entre les diff√©rentes strat√©gies? D√©taillez.
+ Quelle strat√©gie avez vous finalement choisie?

Lancez √† nouveau le programme. Vous devriez voir les images binaris√©es se 
pr√©senter. 

‚úç R√©pondez aux questions suivantes :
+ Quel est maintenant le type des donn√©es de l'image ?
+ Observez ces diff√©rentes images. Les cubes sont ils enti√®rement classifi√©s comme tels ? Qu'en est il des √©critures se trouvant sur les faces ?
+ La segmentation vous semble elle satisfaisante par rapport au probl√™me ?

A la fin de l'algorithme chaque partie blanche contigu√´ est s√©par√©e pour cr√©er
un masque cens√© couvrir un cube. 

‚úç Observez attentivement les images issues de l'op√©ration de seuillage. Voyez-vous des zones qui pourraient √™tre s√©par√©es alors qu'elles ne couvrent pas un cube entier ?

Pour am√©liorer cette √©bauche de segmentation, nous allons utiliser deux
op√©rations _morphologiques_ appel√©es _closing_ et _opening_.

‚úç R√©pondez aux questions suivantes :
+ Quelle est la signification de ces op√©rations ? D√©taillez.
+ En quoi pensez vous que ces op√©rations puissent am√©liorer notre segmentation ?
+ Quelle est l'utilit√© du param√®tre de voisinage ? Comment pensez vous pouvoir le r√©gler ?

Les librairies `scikit-image` et `scipy` contiennent toutes les deux des
impl√©mentations de ces op√©rations. L'une est beaucoup plus rapide que l'autre.

üêç Remplissez les fonctions `perform_closing` et `perform_opening`. Essayez les fonctions des deux librairies susmentionn√©es.

‚úç R√©pondez aux questions suivantes :
+ Quelle impl√©mentations vous semble la plus rapide entre les deux ?
+ Comment avez vous r√©gl√© le param√®tre de voisinage? Quelle valeur avez vous choisi ? 

Ex√©cutez le script a nouveau. Vous devriez voir les images binaires apr√®s
nettoy√©es appara√Ætre. 

‚úç R√©pondez aux questions suivantes :
+ Les d√©fauts de l'image binaire ont ils disparu ?
+ La segmentation vous semble t elle satisfaisante ?

Suite √† cela, l'algorithme utilise la fonction `ndimage.label` de `scipy` qui
s√©pare les diff√©rentes composantes contigu√´s d'une image binaire. Chaque
composante contigu√´ est ensuite nettoy√© pour la phase suivante de l'algorithme
gr√¢ce a la fonction `clean_shape`. A la sortie de cette fonction, l'image doit
√™tre parfaitement nettoy√©e, pour que la zone soit ne contienne aucune tache
sombre, et soit relativement lisse, comme sur cette image:

![img](img/../clean_shape.png)

üêç Remplissez la fonction `clean_shape`. Quelles m√©thodes avez vous utilis√© pour nettoyer la forme ? 

### 1.3 Recherche des contours

Pour continuer, nous devons transformer ces masques binaires en information
g√©om√©triques sur la position des coins du cube dans l'image. Pour faire cela,
nous allons utiliser un algorithme de d√©tection de contours.

La fonction `get_box_contours` contient la logique d'extraction des coins.
L'algorithme passe par les √©tapes suivantes, pour chacun des masques:
+ Un contour initial, contenant de nombreux points est g√©n√©r√©
+ Ce contour est simplifi√© pour ne garder que quatre √©l√©ments repr√©sentant les
  coins du cube.
  
La librairie `scikit-image` contient un algorithme permettant de chercher des
contours dans une image binaire.

üêç Remplissez la fonction `extract_raw_contour`.

Le contour r√©cup√©r√© par la fonction `extract_raw_contour` contient un grand
nombre d'√©l√©ments. Cependant, pour la suite de notre algorithme, nous devons
pouvoir extraire les quatre coins de cet ensemble de points, pour ne garder
qu'eux.

üêç  Remplissez la fonction `simplify_raw_contour`.

‚úç R√©pondez aux questions suivantes : 
+ Quelles strat√©gie avez vous adopt√© pour extraire les coins ? 
+ Relancez le script pour faire d√©filer quelques images dont les coins ont √©t√© d√©tect√©s. Comment marche votre algorithme ?

### 1.4 Extraction des vignettes

Maintenant que nous avons la position des coins, nous allons extraire de l'image
originale, des vignettes de la m√™me taille que les images du dataset MNIST. Cela
permettra, dans la suite du tp, d'envoyer directement les imagettes au r√©seau de 
neurones pour que le label soit reconnu. Pour cela, nous allons effectuer une
transformation projective de la zone d√©limit√©e par les coin, en une image plate 
de 28 par 28 pixels.

‚úç Repondez √† la question suivante :
+ Qu'est ce qu'une transformation projective ?

La biblioth√®que contient une fonction permettant de calculer une transformation
projective √† partir des positions des points de d√©part et d'arriv√©e, et de
transporter l'image d'un espace √† l'autre. Cherchez dans la documentation cet
ensemble de fonctions.

üêç Remplissez les fonctions `compute_transform` et `transform_image`.

Ex√©cutez le script, vous devriez voir d√©filer les images extraites. 

üñºÔ∏è Enregistrez quelques exemples d'imagettes extraites par votre algorithme.

üëÄ Vous avez maintenant une vision compl√®te sur l'algorithme d'extraction des
imagettes. Dans le cours de ce matin, nous avons expliqu√© que la pour cr√©er un
tel programme, sans utiliser de donn√©es (ou tr√©s peu), nous avons besoin de
faire des hypoth√®ses sur les donn√©es.

‚úç  Repondez aux questions suivantes :
+ Sur quelles hypoth√®ses est bas√© l'algorithme d'extraction de vignettes ? 
+ Dans les donn√©es d'essais dont nous disposons, arrive-t-il que ces hypoth√®ses soient bris√©es ?
+ Pouvez vous penser √† des situations dans laquelle notre robot pourrait se trouver, qui briseraient √©galement ces hypoth√®ses ?

Vous pouvez enregistrer votre fichier et le laisser tel quel pour le moment.

## 2. Challenge d√©tection

Pour l'instant notre algorithme est capable d'extraire les imagettes lorsque les
cubes sont sur un fond sombre. Ce n'est probablement pas le genre de sc√®ne dans
laquelle nous voulons faire √©voluer notre robot.

üêç Toujours dans `detection.py` remplacez la ligne suivante :
```python
test_data = glob.glob('../data/ergo_cubes/dark/*.png')
```
par cette ligne:
```python
test_data = glob.glob('../data/ergo_cubes/challenge/*.png')
```

Ex√©cutez le programme tel quel. Vous devriez voir s'afficher de nouvelles images
plus r√©alistes.

‚úç R√©pondez aux questions suivantes :
+ Comment se d√©brouille l'algorithme sur ces nouvelles donn√©es ? 
+ Quelles hypoth√®ses pr√©c√©dentes sont bris√©es par ces nouvelles donn√©es ?

Pendant ce challenge, vous allez d√©velopper un nouvel algorithme de segmentation
qui devrait avoir de meilleures performances sur ces images plus r√©alistes. √Ä la
diff√©rence du pr√©c√©dent algorithme qui n'exploitait que les niveaux de gris pour
segmenter l'image, nous allons maintenant utiliser un algorithme qui utilise la
couleur. 

L'algorithme va suivre les √©tapes suivantes :
+ Tout d'abord, l'image est segment√©e en utilisant les images rgb
+ Cette segmentation est nettoy√©e pour faire dispara√Ætre les artefacts de
  segmentation
+ Chaque objet de la segmentation est analys√© pour d√©terminer si oui ou non il
  correspond √† un cube.

### 2.1 Impl√©mentation

üêç Commencez par remplacer les lignes suivantes de la partie _main_:
```python
for im in images:
    im = segment_thresholding(im, debug=True) 
...
for i, im in enumerate(images):
    ctrs.append(get_box_contours(im, segment_thresholding, debug=True))
...
```

Par les lignes suivantes:
```python
for im in images:
    im = segment_colors(im, debug=True) 
...
for i, im in enumerate(images):
    ctrs.append(get_box_contours(im, segment_colors, debug=True))
...
```

Maintenant, √† votre tour.

üëÄ Observez la fonction `segment_colors` et retrouvez la structure de l'algorithme pr√©sent√© ci dessus. 

üêç Impl√©mentez les fonctions `build_segmented_image`, `clean_shape` et `is_cube`. 

‚úç Dans un cours paragraphe, d√©taillez vos solutions, et les hypoth√®ses qu'elle exploite sur les donn√©es.

üéûÔ∏è Une fois le programme aboutit, faite une video montrant votre algorithme en fonctionnement sur les anciennes, ainsi que les nouvelles images, que vous integrerez √† votre rendu.

## 3. Partie apprentissage

Nous allons maintenant nous int√©resser √† la partie r√©seaux de neurones
permettant d'extraire les labels √† partir des imagettes. Comme expliqu√© ce matin
dans la pr√©sentation, nous utiliserons le jeu de donn√©e _mnist_ pour entrainer
notre mod√®le. 

Commencez par ouvrir le fichier `learning.py`.

### 3.1 Chargement des donn√©es

Prenez connaissance du code, puis lancez le en ex√©cutant √† la ligne de commande :
```
python learning.py
```

‚úç Observez la fonction `load_data`, r√©pondez aux questions suivantes : 
+ Que contiennent les variables `x_train` et `y_train` ?
+ Pourquoi la fonction `load_data` renvoie-t-elle √©galement les variables `x_test` et `y_test` ?
+ Quelles sont les formes respectives de `x_train` et `y_train` ? 
+ Pouvez vous expliquer √† quoi correspondent chacune des dimensions de ces deux tableaux ?
+ Quelles sont les valeurs minimales et maximales de ces deux tableaux ? De quel type sont les donn√©es ? Expliquez.

### 3.2 Pr√©-visualisation des donn√©es brutes

üëÄ Appuyez sur entr√©e pour continuer, et observez les images. 

‚úç R√©pondez aux questions suivantes :
+ Quelle sont les valeurs des pixels blancs (repr√©sent√©s en jaune) et des pixels noirs ? 
+ Observez bien les donn√©es et leurs labels. Toutes les images sont-elles simples √† classifier correctement ? 
+ Ferriez vous des erreurs en les classifiant ?

### 3.3 Pr√©paration des donn√©es

Au d√©but de son entra√Ænement, un r√©seau de neurones fonctionne bien lorsque les
donn√©es d'entr√©e sont centr√©es autour de 0 et ont un √©cart type de 1. Si ce
n'est pas le cas, les vecteurs de biais des diff√©rentes couches vont lentement
se modifier pour s'adapter aux donn√©es, mais cette √©tape est longue et gaspille
du temps de calcul inutilement. Il faut donc transformer nos donn√©es pour
qu'elles respectent ces pr√©-requis.

De plus, la premi√®re couche √©tant une couche de convolution, elle travaille
normalement avec des images ayant plusieurs canaux (RGB) encod√©s sur la derni√®re
dimension du tableau, ce qui n'est pas le cas de notre jeu de donn√©e. Il faut
donc modifier la forme de votre tableau pour la rendre compatible avec
l'op√©ration de convolution.

üêç Remplissez la fonction `prepare_input`.

Ex√©cutez le script. Vous devriez voir s'afficher le informations sur le tableau
pr√©par√©.

‚úç R√©pondez aux questions suivantes :
+ Quelle est la forme de `x_train` maintenant ?
+ Quelles sont les valeurs min et max ? Est ce que cela convient bien √† notre pr√©-requis?
+ Le type de donn√©e devrait avoir chang√©? Quel est il? Sur quel type de donn√©e pensez vous qu'un r√©seau de neurone travaille?

Il reste √† pr√©parer les donn√©es de sortie. Pour l'instant, votre vecteur de
sortie `y_train` contient des entiers repr√©sentant le label de l'image.
Cependant pour fonctionner, notre r√©seau de neurones n√©cessite des donn√©es sous
la forme _one hot encoding_.

‚úç R√©pondez aux questions suivantes :
+ Qu'est ce qu'un one-hot-encoding ? En quoi est ce diff√©rent des donn√©es dont nous disposons actuellement ?
+ Observez la fonction `load_data`. A quoi sert la variable globale `CLASSES` ?

üêç Remplissez la fonction `prepare_output`.

‚úç R√©pondez aux questions suivantes :
+ Quelle est la forme de `y_train` maintenant ?
+ Quelles sont les valeurs min et max ? Est ce que cela convient bien √† notre pr√©-requis ?

### 3.4 Pr√©-visualisation des donn√©es pr√©par√©es

üëÄ Ex√©cutez le script et observez les donn√©es pr√©par√©es.

‚úç  R√©pondez aux questions suivantes :
+ Quelles sont les valeurs des pixels blanc et des pixels noirs maintenant ?
+ Quelles sont les valeurs des labels maintenant ? Comprenez-vous leur signification sur cet exemple ?

### 3.5 Le mod√®le

Maintenant, vous allez devoir d√©finir le mod√®le _LeNet5_ que nous avons vu
pendant le cours.

üêç Remplissez la fonction `build_model`.

üëÄ Ex√©cutez le script √† nouveau et observez le r√©sum√© du mod√®le. 

‚úç R√©pondez aux questions suivantes:
+ Observez le nombre de param√®tres par couche. Quelles sont les couches qui ont le plus grand nombre de param√®tres ?
+ Cela vous semble t il normal ?
+ Qu'en concluez vous sur l'utilit√© des couches par convolution ? 

### 3.6 La fonction de co√ªt et l'optimiseur

Durant la pr√©sentation, nous avons vu que deux fonctions de co√ªt sont
r√©guli√®rement utilis√©es dans l'entra√Ænement des r√©seaux de neurones:
+ L'erreur quadratique moyenne (Mean squared error)
+ L'entropie crois√©e (Cross entropy)

‚úç Repondez √† la question suivante :
+ Quelle fonction de co√ªt vous semble adapt√©e √† notre probl√®me ?

üêç Remplissez la fonction `get_loss` pour impl√©menter la fonction de co√ªt adapt√©e. 

Pendant la pr√©sentation, nous avons vu que l'optimiseur est l'algorithme qui
permet de se d√©placer sur la surface dessin√©e par la fonction de co√ªt dans
l'espace des param√®tres. Cet algorithme permet de chercher l'endroit o√π la
fonction de co√ªt est minimale. 

Un des algorithmes les plus simples s'appelle la __descente de gradient__ (GD)
et consiste √† se d√©placer dans le sens de la pente la plus forte √† chaque pas de
temps.

‚úç R√©pondez aux questions suivantes:
+ Dans quelle hypoth√®se cet algorithme permet il de trouver le minimum global de la fonction de co√ªt selon vous ?
+ Pensez vous que cette hypoth√®se soit v√©rifi√©e pour les r√©seaux de neurones ?
+ Que se passe-t-il si cette hypoth√®se n'est pas v√©rifi√©e ? 

__Adam__ est un optimiseur plus complexe que GD. Sur l'image suivante, on voit
plusieurs optimiseurs se d√©placer sur une fonction de co√ªt:

![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie11.gif)

‚úç R√©pondez √† la question suivante :
+ Concentrez vous sur Adam et GD. Quelle semble √™tre la caract√©ristique de Adam compar√©e a GD ? 

Une autre caract√©ristique de l'algorithme GD, est que la taille du pas qui est
effectu√© √† chaque it√©ration est fixe. L'image suivante montre Adam et GD dans un
cas ou la pente devient tr√©s forte:

![cette image](https://github.com/Jaewan-Yun/optimizer-visualization/raw/master/figures/movie9.gif)

‚úç Repondez aux questions suivantes: 
+ GD arrive-t-il √† converger ? Comprenez vous pourquoi ?
+ Adam ne semble pas soumis au m√™me probl√™me que GD ? Quelle autre caract√©ristique de Adam cela montre-t-il ? 
+ Quelle conclusion pouvez vous tirer sur l'utilit√© de GD pour entra√Æner des r√©seaux de neurones ?

Maintenant √† vous de jouer.

üêç Remplissez la fonction `get_optimizer`.

### 3.7 Entrainement

Relancez le code et appuyez sur entr√©e jusqu'au d√©clenchement de la partie 3.7.
üëÄ Vous devriez voir les it√©rations d'entra√Ænement se succ√©der.

‚úç R√©pondez aux questions suivantes:
+ Observez l'√©volution de la pr√©cision sur l'ensemble d'entra√Ænement et l'ensemble de test. Les valeurs sont elles identiques ?
+ √Ä partir de combien d'√©poques le r√©seau est il entra√Æn√© selon vous ?
+ En r√©glant le nombre d'it√©ration d'apprentissage dans le code (argument `epochs` de la fonction fit), arrivez vous √† observer une phase de sur-apprentissage ?

### 3.8 Poids appris

üëÄ Appuyez sur entr√©e pour visualiser les noyaux appris par le r√©seau de neurones. 

‚úç R√©pondez aux questions suivantes:
+ En observant les noyaux de la premi√®re couche, arrivez vous √† distinguer le genre de features qui seront extraites par chacun des noyaux?
+ Pouvez vous en faire de m√™me pour la deuxi√®me couche ?

### 3.9 Activations

üëÄ Appuyez sur entr√©e, puis entrez un indice (un entier de n'importe quelle valeur
inf√©rieure a 5000).

‚úç R√©pondez aux questions suivantes:
+ Apr√®s la premi√®re couche de convolution, les features extraites correspondent-elles √† celles que vous imaginiez ?
+ Apr√®s la premi√®re couche de pooling, les features pr√©sentes auparavant sont-elles conserv√©es ?
+ Apr√®s la deuxi√®me couche de pooling, diriez vous que de l'information spatiale est toujours pr√©sente ? Autrement dit, les activations ressemblent-elles toujours √† des images ?

### 3.10 Entrainement final

‚ùå Arr√™tez le script en appuyant sur `ctrl+c`. Jusqu'√† pr√©sent, nous avons
travaill√© sur l'ensemble des donn√©es, mais pour la suite nous n'aurons besoin
que des images de 1 et de 2. Changez la valeur de la variable `CLASSES` pour ne
garder que les classes qui nous int√©ressent, entra√Ænez en r√©seau, puis
sauvegardez le dans un fichier.

## 4. Int√©gration

‚ÜîÔ∏è Il est maintenant temps d'int√©grer les deux parties du pipeline pour
l'utilisation finale. Ouvrez le fichier `main.py` √† la racine du projet. Pour
que les deux parties du pipeline s'adaptent correctement, il faut que les
vignettes renvoy√©es par la partie d√©tection ressemblent aux images du dataset
mnist (dans leur valeurs, leur type, etc).

üêç Remplissez la fonction `preprocess`.

üëÄ Une fois que cela est fait, ex√©cutez le script. Vous devriez pouvoir examiner la
performance de votre algorithme complet sur les images de test.

‚úç R√©pondez aux questions suivantes :
+ Quelles sont les performances de l'algorithme global ?
+ Observez-vous des sources de bugs dans l'algorithme ?

ü§ñ Enfin, en vous connectant √† Poppy Ergo Jr, r√©cup√©rez quelque images des cubes dans
votre propre environnement, puis d√©posez les dans `data/ergo_cubes/perso`.
Lancez le programme et observez la performance de votre algorithme sur les
donn√©es de votre propre environnement.

‚úç R√©pondez aux questions suivantes :
+ Quelles sont les performances de l'algorithme sur vos donn√©es ? 
+ Sont elles comparables aux performances sur les exemples dont nous disposons ? 

‚ÑπÔ∏è Nous avons vu que le sur-apprentissage est une des difficult√©s les plus
importantes dans l'utilisation des algorithmes d'apprentissage. Lorsque vous
avez r√©gl√© votre programme de d√©tection, vous l'avez fait en utilisant
l'ensemble des donn√©es dont vous disposiez, sans garder de groupe test s√©par√©.
Cette mani√®re de faire peut √©galement mener √† du sur-apprentissage, mais cette
fois, de votre part, dans le r√©glage de votre algorithme. Le sur-apprentissage
n'est donc pas r√©serv√© aux algorithmes mais est plut√¥t une des difficult√©s de la
programmation bas√©e sur les donn√©es. Que ce soit un humain ou un programme, le
r√©glage de param√®tres en fonction de donn√©es conna√Æt les m√™mes d√©fauts.

‚ÑπÔ∏è De mani√®re g√©n√©rale, il est futile d'attendre de ce type de programme qu'il
extrapole √† des donn√©es (des situations) qui n'ont pas √©t√© pr√©sent√©es pendant
l'apprentissage. Il est donc important, lors du d√©veloppement de ce type de
programme, de pr√©voir une phase de r√©colte de donn√©e importante, dont on
s'assure qu'elle couvrira bien les usages futures du programme.
